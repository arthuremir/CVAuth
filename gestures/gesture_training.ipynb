{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from torch.utils.data import Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fist\t      four_fingers  ok\t\tthree_fingers\r\n",
      "five_fingers  noise\t    one_finger\ttwo_fingers\r\n"
     ]
    }
   ],
   "source": [
    "!ls gesture_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomAffine(25, \n",
    "                                (0.15, 0.15),\n",
    "                                (0.7, 1.1)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "gestures_dataset = datasets.ImageFolder(root='gesture_data',\n",
    "                                           transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(gestures_dataset,\n",
    "                                             batch_size=32, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f137148e7b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(gestures_dataset[360][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(gestures_dataset)\n",
    "\n",
    "val_size = .2\n",
    "val_length = int(dataset_length * val_size)\n",
    "\n",
    "train_data_raw, val_data_raw = random_split(gestures_dataset, [dataset_length - val_length, val_length])\n",
    "\n",
    "assert isinstance(train_data_raw, torch.utils.data.Dataset)\n",
    "assert isinstance(val_data_raw, torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_data_raw, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_data_raw, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, num_classes)\n",
    "model.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 12 16:03:25 2020 Epoch: 1\n",
      "Epoch 1, train loss: 2.1376, valid loss: 2.1965.\n",
      "Validation loss decreased (inf --> 2.196508).  Saving model ...\n",
      "Sun Jan 12 16:03:27 2020 Epoch: 2\n",
      "Epoch 2, train loss: 1.9763, valid loss: 1.6615.\n",
      "Validation loss decreased (2.196508 --> 1.661458).  Saving model ...\n",
      "Sun Jan 12 16:03:29 2020 Epoch: 3\n",
      "Epoch 3, train loss: 1.5526, valid loss: 1.3355.\n",
      "Validation loss decreased (1.661458 --> 1.335529).  Saving model ...\n",
      "Sun Jan 12 16:03:32 2020 Epoch: 4\n",
      "Epoch 4, train loss: 1.1954, valid loss: 1.0047.\n",
      "Validation loss decreased (1.335529 --> 1.004742).  Saving model ...\n",
      "Sun Jan 12 16:03:34 2020 Epoch: 5\n",
      "Epoch 5, train loss: 0.8924, valid loss: 0.8406.\n",
      "Validation loss decreased (1.004742 --> 0.840587).  Saving model ...\n",
      "Sun Jan 12 16:03:37 2020 Epoch: 6\n",
      "Epoch 6, train loss: 0.7100, valid loss: 0.7249.\n",
      "Validation loss decreased (0.840587 --> 0.724946).  Saving model ...\n",
      "Sun Jan 12 16:03:40 2020 Epoch: 7\n",
      "Epoch 7, train loss: 0.5442, valid loss: 0.6122.\n",
      "Validation loss decreased (0.724946 --> 0.612176).  Saving model ...\n",
      "Sun Jan 12 16:03:43 2020 Epoch: 8\n",
      "Epoch 8, train loss: 0.5188, valid loss: 0.6149.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:03:45 2020 Epoch: 9\n",
      "Epoch 9, train loss: 0.5724, valid loss: 0.5926.\n",
      "Validation loss decreased (0.612176 --> 0.592628).  Saving model ...\n",
      "Sun Jan 12 16:03:48 2020 Epoch: 10\n",
      "Epoch 10, train loss: 0.5334, valid loss: 0.6136.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:03:50 2020 Epoch: 11\n",
      "Epoch 11, train loss: 0.4195, valid loss: 0.4970.\n",
      "Validation loss decreased (0.592628 --> 0.496988).  Saving model ...\n",
      "Sun Jan 12 16:03:54 2020 Epoch: 12\n",
      "Epoch 12, train loss: 0.5314, valid loss: 0.4990.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:03:56 2020 Epoch: 13\n",
      "Epoch 13, train loss: 0.4603, valid loss: 0.4933.\n",
      "Validation loss decreased (0.496988 --> 0.493312).  Saving model ...\n",
      "Sun Jan 12 16:03:58 2020 Epoch: 14\n",
      "Epoch 14, train loss: 0.4543, valid loss: 0.3960.\n",
      "Validation loss decreased (0.493312 --> 0.395990).  Saving model ...\n",
      "Sun Jan 12 16:04:01 2020 Epoch: 15\n",
      "Epoch 15, train loss: 0.3174, valid loss: 0.4246.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:03 2020 Epoch: 16\n",
      "Epoch 16, train loss: 0.2743, valid loss: 0.4229.\n",
      "2 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:05 2020 Epoch: 17\n",
      "Epoch 17, train loss: 0.2682, valid loss: 0.2827.\n",
      "Validation loss decreased (0.395990 --> 0.282745).  Saving model ...\n",
      "Sun Jan 12 16:04:07 2020 Epoch: 18\n",
      "Epoch 18, train loss: 0.2462, valid loss: 0.4266.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:09 2020 Epoch: 19\n",
      "Epoch 19, train loss: 0.2430, valid loss: 0.3180.\n",
      "2 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:11 2020 Epoch: 20\n",
      "Epoch 20, train loss: 0.1899, valid loss: 0.4008.\n",
      "3 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:13 2020 Epoch: 21\n",
      "Epoch 21, train loss: 0.2477, valid loss: 0.4246.\n",
      "4 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:15 2020 Epoch: 22\n",
      "Epoch 22, train loss: 0.1841, valid loss: 0.2444.\n",
      "Validation loss decreased (0.282745 --> 0.244382).  Saving model ...\n",
      "Sun Jan 12 16:04:18 2020 Epoch: 23\n",
      "Epoch 23, train loss: 0.1861, valid loss: 0.3492.\n",
      "1 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:20 2020 Epoch: 24\n",
      "Epoch 24, train loss: 0.2157, valid loss: 0.2660.\n",
      "2 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:22 2020 Epoch: 25\n",
      "Epoch 25, train loss: 0.1222, valid loss: 0.4046.\n",
      "3 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:24 2020 Epoch: 26\n",
      "Epoch 26, train loss: 0.2011, valid loss: 0.3778.\n",
      "4 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:26 2020 Epoch: 27\n",
      "Epoch 27, train loss: 0.2130, valid loss: 0.3233.\n",
      "5 epochs of increasing val loss\n",
      "Sun Jan 12 16:04:28 2020 Epoch: 28\n",
      "Epoch 28, train loss: 0.1758, valid loss: 0.3532.\n",
      "6 epochs of increasing val loss\n",
      "Stopping training\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "patience = 5\n",
    "n_epochs = 200\n",
    "\n",
    "#early_stopping_counter\n",
    "es_counter = 0\n",
    "\n",
    "stop = False\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "    train_loss = []\n",
    "    train_auc = []\n",
    "\n",
    "    for batch_i, sample_batch in enumerate(train_loader):\n",
    "        \n",
    "        #print(sample_batch)\n",
    "        \n",
    "        data, target = sample_batch[0].cuda(), sample_batch[1].cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        #NEVER WRITE LIKE THIS!!!\n",
    "        #train_loss.append(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    for batch_i, sample_batch in enumerate(val_loader):\n",
    "        \n",
    "        data, target = sample_batch[0].cuda(), sample_batch[1].cuda()\n",
    "        \n",
    "        #print(data.shape)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        val_loss.append(loss.item()) \n",
    "\n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n",
    "    \n",
    "    valid_loss = np.mean(val_loss)\n",
    "    #scheduler.step(valid_loss)\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'best_model_2.pth')\n",
    "        valid_loss_min = valid_loss\n",
    "        p = 0\n",
    "\n",
    "    if valid_loss > valid_loss_min:\n",
    "        p += 1\n",
    "        print(f'{p} epochs of increasing val loss')\n",
    "        if p > patience:\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "            break        \n",
    "            \n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(gestures_dataset[156][0][None, :, :].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3224,  3.1439,  7.8519, -3.6501, -0.3455, -1.4688,  5.5941, -0.7817]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './best_model_2.pth'\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "model.fc = torch.nn.Linear(512, num_classes)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_num = 0\n",
    "\n",
    "time_start = time.time()\n",
    "for val_batch in val_loader:\n",
    "    \n",
    "    \n",
    "    inputs, labels = val_batch[0].cuda(), val_batch[1].cuda()\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    pred_num += (labels==predicted).sum()\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time: 0.57\n",
      "Accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation time: {:.2f}\".format(time_end - time_start))\n",
    "print(\"Accuracy: {:.4f}\". format(int(pred_num)/val_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'torch2trt'...\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 1428 (delta 8), reused 11 (delta 4), pack-reused 1411\u001b[K\n",
      "Receiving objects: 100% (1428/1428), 272.97 KiB | 913.00 KiB/s, done.\n",
      "Resolving deltas: 100% (870/870), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarks  LICENSE.md\tREADME.md  test.sh\r\n",
      "build.py    notebooks\tsetup.py   torch2trt\r\n"
     ]
    }
   ],
   "source": [
    "!ls torch2trt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\r\n",
      "running build\r\n",
      "running install_egg_info\r\n",
      "running egg_info\r\n",
      "creating torch2trt.egg-info\r\n",
      "writing torch2trt.egg-info/PKG-INFO\r\n",
      "writing dependency_links to torch2trt.egg-info/dependency_links.txt\r\n",
      "writing top-level names to torch2trt.egg-info/top_level.txt\r\n",
      "writing manifest file 'torch2trt.egg-info/SOURCES.txt'\r\n",
      "reading manifest file 'torch2trt.egg-info/SOURCES.txt'\r\n",
      "writing manifest file 'torch2trt.egg-info/SOURCES.txt'\r\n",
      "Copying torch2trt.egg-info to /home/user/anaconda3/envs/envi/lib/python3.7/site-packages/torch2trt-0.0.3-py3.7.egg-info\r\n",
      "running install_scripts\r\n"
     ]
    }
   ],
   "source": [
    "!python torch2trt/setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3f7e7e224fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch2trt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch2trt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/assignment2/torch2trt/torch2trt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtorch2trt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/assignment2/torch2trt/torch2trt/torch2trt.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcalibration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBatchDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetCalibrator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_CALIBRATION_ALGORITHM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-8dfd087091e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
